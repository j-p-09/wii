<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AGENT INTERFACE | FACIAL RECOGNITION</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        :root {
            --agent-green: #00ff41;
            --agent-dark: #0a0a0a;
            --agent-border: #113311;
        }

        body {
            background-color: var(--agent-dark);
            color: var(--agent-green);
            font-family: 'Courier New', Courier, monospace;
            margin: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            overflow-x: hidden;
            text-transform: uppercase;
        }

        /* Scanline Effect */
        body::before {
            content: " ";
            display: block;
            position: absolute;
            top: 0; left: 0; bottom: 0; right: 0;
            background: linear-gradient(rgba(18, 16, 16, 0) 50%, rgba(0, 0, 0, 0.25) 50%), linear-gradient(90deg, rgba(255, 0, 0, 0.06), rgba(0, 255, 0, 0.02), rgba(0, 0, 255, 0.06));
            z-index: 2;
            background-size: 100% 2px, 3px 100%;
            pointer-events: none;
        }

        .container {
            width: 90%;
            max-width: 1000px;
            border: 2px solid var(--agent-green);
            padding: 20px;
            background: rgba(0, 20, 0, 0.8);
            box-shadow: 0 0 20px rgba(0, 255, 65, 0.2);
            position: relative;
            z-index: 3;
        }

        h1 {
            text-align: center;
            letter-spacing: 5px;
            border-bottom: 1px solid var(--agent-green);
            padding-bottom: 10px;
            margin-top: 0;
        }

        .upload-section {
            display: flex;
            justify-content: space-around;
            gap: 20px;
            margin-top: 30px;
        }

        .image-card {
            width: 300px;
            height: 350px;
            border: 1px solid var(--agent-green);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
            background: #000;
        }

        .image-card img {
            max-width: 100%;
            max-height: 100%;
            display: none;
        }

        .image-card.scanning::after {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 4px;
            background: var(--agent-green);
            box-shadow: 0 0 15px var(--agent-green);
            animation: scan 2s infinite linear;
        }

        @keyframes scan {
            0% { top: 0; }
            100% { top: 100%; }
        }

        .controls {
            margin-top: 30px;
            text-align: center;
        }

        input[type="file"] {
            display: none;
        }

        .btn {
            background: transparent;
            color: var(--agent-green);
            border: 1px solid var(--agent-green);
            padding: 10px 20px;
            cursor: pointer;
            font-family: inherit;
            transition: 0.3s;
            margin: 5px;
        }

        .btn:hover {
            background: var(--agent-green);
            color: #000;
            box-shadow: 0 0 10px var(--agent-green);
        }

        #result-display {
            margin-top: 20px;
            font-size: 24px;
            font-weight: bold;
            text-align: center;
            height: 40px;
        }

        .status-bar {
            margin-top: 10px;
            font-size: 12px;
            color: #008800;
        }

        .loader {
            color: #fff;
            background: red;
            padding: 5px;
            display: inline-block;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>

    <div id="loading-overlay" class="loader">SYSTEM INITIALIZING: LOADING AI MODELS...</div>

    <div class="container">
        <h1>Face Identity Analysis</h1>
        
        <div class="upload-section">
            <div class="image-card" id="card1">
                <span id="label1">Subject A</span>
                <img id="img1" src="#" alt="Subject 1">
                <button class="btn" onclick="document.getElementById('file1').click()">Upload</button>
                <input type="file" id="file1" accept="image/*">
            </div>

            <div class="image-card" id="card2">
                <span id="label2">Subject B</span>
                <img id="img2" src="#" alt="Subject 2">
                <button class="btn" onclick="document.getElementById('file2').click()">Upload</button>
                <input type="file" id="file2" accept="image/*">
            </div>
        </div>

        <div class="controls">
            <button class="btn" id="analyze-btn" disabled>Run Biometric Match</button>
            <div id="result-display">READY FOR INPUT</div>
            <div class="status-bar" id="status">System Status: Awaiting Data...</div>
        </div>
    </div>

    <script>
        const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';
        const analyzeBtn = document.getElementById('analyze-btn');
        const statusText = document.getElementById('status');
        const resultDisplay = document.getElementById('result-display');

        // 1. Load the AI Models
        async function loadModels() {
            try {
                await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
                await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
                await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
                document.getElementById('loading-overlay').style.display = 'none';
                statusText.innerText = "System Status: Models Loaded. Ready.";
                analyzeBtn.disabled = false;
            } catch (e) {
                statusText.innerText = "Error loading AI models. Check internet connection.";
            }
        }

        loadModels();

        // 2. Handle Image Previews
        function handleImage(input, imgId, labelId) {
            input.addEventListener('change', (e) => {
                const file = e.target.files[0];
                if (file) {
                    const reader = new FileReader();
                    reader.onload = (f) => {
                        const img = document.getElementById(imgId);
                        img.src = f.target.result;
                        img.style.display = 'block';
                        document.getElementById(labelId).style.display = 'none';
                    };
                    reader.readAsDataURL(file);
                }
            });
        }

        handleImage(document.getElementById('file1'), 'img1', 'label1');
        handleImage(document.getElementById('file2'), 'img2', 'label2');

        // 3. The Comparison Logic
        analyzeBtn.addEventListener('click', async () => {
            const img1 = document.getElementById('img1');
            const img2 = document.getElementById('img2');

            if (!img1.src || img1.src.includes('#') || !img2.src || img2.src.includes('#')) {
                alert("Please upload both images first!");
                return;
            }

            // Visual scanning effect
            document.getElementById('card1').classList.add('scanning');
            document.getElementById('card2').classList.add('scanning');
            resultDisplay.innerText = "ANALYZING...";
            statusText.innerText = "Status: Extracting facial descriptors...";

            try {
                // Get facial descriptors for both images
                const desc1 = await faceapi.allFacesSsdMobilenetv1(img1);
                const desc2 = await faceapi.allFacesSsdMobilenetv1(img2);

                const fullDesc1 = await faceapi.computeFaceDescriptor(img1);
                const fullDesc2 = await faceapi.computeFaceDescriptor(img2);

                if (!fullDesc1 || !fullDesc2) {
                    resultDisplay.innerText = "ERROR: FACE NOT DETECTED";
                    statusText.innerText = "Status: Failed to find a clear face in one or both images.";
                } else {
                    // Calculate distance (0 is perfect match, 1 is totally different)
                    const distance = faceapi.euclideanDistance(fullDesc1, fullDesc2);
                    
                    // Convert distance to a percentage (Inverse logic)
                    // Usually distance < 0.6 is considered the same person
                    let matchScore = (1 - distance) * 100;
                    if (matchScore > 99) matchScore = 99.9;
                    if (matchScore < 0) matchScore = 0.5;

                    resultDisplay.innerText = `MATCH: ${matchScore.toFixed(2)}%`;
                    statusText.innerText = `Status: Analysis Complete. Distance Delta: ${distance.toFixed(4)}`;
                }
            } catch (err) {
                console.error(err);
                resultDisplay.innerText = "SYSTEM ERROR";
            }

            document.getElementById('card1').classList.remove('scanning');
            document.getElementById('card2').classList.remove('scanning');
        });
    </script>
</body>
</html>
